{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d78327",
   "metadata": {},
   "source": [
    "# How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a168e7",
   "metadata": {},
   "source": [
    "    * I apply this guidelines for my project, working with wine quality prediction database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a8313",
   "metadata": {},
   "source": [
    "Grid search is a model hyperparameter optimization technique. In scikit-learn this technique is provided in the GridSearchCV class. By default, accuracy is the score that is optimized, but other scores can be specified in the score argument of the GridSearchCV constructor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d77bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import matplotlib.pyplot as plt    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from tensorflow import keras \n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d71070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 11)\n",
      "(6497,)\n"
     ]
    }
   ],
   "source": [
    "#Import and standardize database\n",
    "\n",
    "df = pd.read_csv(\"wine.csv\", index_col = \"index\")\n",
    "X = df.iloc[:, 0:11]\n",
    "df['quality'] = df['quality'].apply(lambda x: 0 if x < 6 else 1)\n",
    "y = df.iloc[:, 11]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.30, stratify=y)\n",
    "# creating normalization object \n",
    "# fit data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9483da",
   "metadata": {},
   "source": [
    "## Use Grid Search in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee002b5",
   "metadata": {},
   "source": [
    "### 1. Tune batch size and training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9d558b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/2679263144.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.772156 using {'batch_size': 80, 'epochs': 50}\n",
      "0.765777 (0.016480) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.771937 (0.012120) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.759842 (0.009972) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.761818 (0.015909) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.767758 (0.015183) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.767101 (0.013513) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.758960 (0.017965) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.771057 (0.009727) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.760943 (0.012870) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.757421 (0.014494) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.766217 (0.013255) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.765782 (0.014891) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.752582 (0.009767) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.772156 (0.012269) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.767760 (0.007015) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.754564 (0.014816) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.767757 (0.016617) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.771275 (0.019015) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# fix random seed for reproducibility\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters: BATCH_SIZE and EPOCHS\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs) #define parameters here\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf109c",
   "metadata": {},
   "source": [
    "### 2. Tune optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e715d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/3687319543.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=80, verbose=0)\n",
      "2021-09-09 11:13:59.650488: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.651394: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.651875: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.652320: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.653307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.655481: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.661387: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:13:59.662717: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.763798 using {'optimizer': 'RMSprop'}\n",
      "0.744665 (0.016036) with: {'optimizer': 'SGD'}\n",
      "0.763798 (0.014067) with: {'optimizer': 'RMSprop'}\n",
      "0.643495 (0.025556) with: {'optimizer': 'Adagrad'}\n",
      "0.517694 (0.091624) with: {'optimizer': 'Adadelta'}\n",
      "0.761159 (0.017830) with: {'optimizer': 'Adam'}\n",
      "0.758521 (0.017875) with: {'optimizer': 'Adamax'}\n",
      "0.759621 (0.018063) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=80, verbose=0)\n",
    "\n",
    "# define the grid search Parameters ###OPTIMIZERS\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)   ##Define changes here\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c054cea",
   "metadata": {},
   "source": [
    "### 3. Tune learning rate and momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "556e586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/1875075457.py:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
      "2021-09-09 11:33:11.282743: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.282749: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.282741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.282779: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.282741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.282741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.284472: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 11:33:11.285899: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.768858 using {'learning_rate': 0.001, 'momentum': 0.9}\n",
      "0.752803 (0.020415) with: {'learning_rate': 0.001, 'momentum': 0.0}\n",
      "0.747743 (0.015601) with: {'learning_rate': 0.001, 'momentum': 0.2}\n",
      "0.755003 (0.014602) with: {'learning_rate': 0.001, 'momentum': 0.4}\n",
      "0.755663 (0.005719) with: {'learning_rate': 0.001, 'momentum': 0.6}\n",
      "0.762919 (0.015904) with: {'learning_rate': 0.001, 'momentum': 0.8}\n",
      "0.768858 (0.007691) with: {'learning_rate': 0.001, 'momentum': 0.9}\n",
      "0.765120 (0.017264) with: {'learning_rate': 0.01, 'momentum': 0.0}\n",
      "0.766219 (0.012790) with: {'learning_rate': 0.01, 'momentum': 0.2}\n",
      "0.764020 (0.013197) with: {'learning_rate': 0.01, 'momentum': 0.4}\n",
      "0.765998 (0.010722) with: {'learning_rate': 0.01, 'momentum': 0.6}\n",
      "0.757642 (0.005719) with: {'learning_rate': 0.01, 'momentum': 0.8}\n",
      "0.746208 (0.007497) with: {'learning_rate': 0.01, 'momentum': 0.9}\n",
      "0.765341 (0.011336) with: {'learning_rate': 0.1, 'momentum': 0.0}\n",
      "0.756323 (0.019120) with: {'learning_rate': 0.1, 'momentum': 0.2}\n",
      "0.749507 (0.008980) with: {'learning_rate': 0.1, 'momentum': 0.4}\n",
      "0.760284 (0.010295) with: {'learning_rate': 0.1, 'momentum': 0.6}\n",
      "0.748185 (0.007573) with: {'learning_rate': 0.1, 'momentum': 0.8}\n",
      "0.717398 (0.009577) with: {'learning_rate': 0.1, 'momentum': 0.9}\n",
      "0.745768 (0.004276) with: {'learning_rate': 0.2, 'momentum': 0.0}\n",
      "0.756104 (0.010475) with: {'learning_rate': 0.2, 'momentum': 0.2}\n",
      "0.766880 (0.009625) with: {'learning_rate': 0.2, 'momentum': 0.4}\n",
      "0.751264 (0.007419) with: {'learning_rate': 0.2, 'momentum': 0.6}\n",
      "0.720699 (0.028256) with: {'learning_rate': 0.2, 'momentum': 0.8}\n",
      "0.724877 (0.019576) with: {'learning_rate': 0.2, 'momentum': 0.9}\n",
      "0.759180 (0.016861) with: {'learning_rate': 0.3, 'momentum': 0.0}\n",
      "0.755006 (0.010827) with: {'learning_rate': 0.3, 'momentum': 0.2}\n",
      "0.751264 (0.005223) with: {'learning_rate': 0.3, 'momentum': 0.4}\n",
      "0.741589 (0.004439) with: {'learning_rate': 0.3, 'momentum': 0.6}\n",
      "0.707940 (0.014289) with: {'learning_rate': 0.3, 'momentum': 0.8}\n",
      "0.667034 (0.041280) with: {'learning_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learning_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learning_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "# define the grid search parameters\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee2bf1",
   "metadata": {},
   "source": [
    "### 4. Tune network weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9a50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/1334812496.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.772945 using {'init_mode': 'lecun_uniform'}\n",
      "0.763902 (0.004660) with: {'init_mode': 'uniform'}\n",
      "0.772945 (0.005743) with: {'init_mode': 'lecun_uniform'}\n",
      "0.765634 (0.003298) with: {'init_mode': 'normal'}\n",
      "0.628052 (0.008115) with: {'init_mode': 'zero'}\n",
      "0.765442 (0.003284) with: {'init_mode': 'glorot_normal'}\n",
      "0.768327 (0.004062) with: {'init_mode': 'glorot_uniform'}\n",
      "0.772560 (0.005341) with: {'init_mode': 'he_normal'}\n",
      "0.771214 (0.005833) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=11, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode= init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a6941",
   "metadata": {},
   "source": [
    "### 5. Tune activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5c6d993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/4246544714.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
      "2021-09-09 12:25:45.968742: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.968780: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.969425: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.969507: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.969747: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.969998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.972564: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-09 12:25:45.980438: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.771497 using {'activation': 'tanh'}\n",
      "0.766880 (0.013339) with: {'activation': 'softmax'}\n",
      "0.760277 (0.021530) with: {'activation': 'softplus'}\n",
      "0.767538 (0.013461) with: {'activation': 'softsign'}\n",
      "0.756322 (0.013529) with: {'activation': 'relu'}\n",
      "0.771497 (0.008779) with: {'activation': 'tanh'}\n",
      "0.763580 (0.014065) with: {'activation': 'sigmoid'}\n",
      "0.757203 (0.008618) with: {'activation': 'hard_sigmoid'}\n",
      "0.759400 (0.017341) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the dropout rate\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=11, kernel_initializer='uniform', activation=activation))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4514fc",
   "metadata": {},
   "source": [
    "### 6. Tune dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0277c57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/809466583.py:24: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=40, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.765338 using {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.757641 (0.019995) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.764679 (0.019234) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "0.762699 (0.018961) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.764019 (0.017586) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.762699 (0.015499) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.754782 (0.020414) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.764238 (0.017329) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.761820 (0.017669) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.764679 (0.014294) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.765338 (0.020782) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.756981 (0.020938) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.763360 (0.017234) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.760501 (0.015114) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.761819 (0.016720) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.762481 (0.015359) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.751923 (0.021172) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.759401 (0.016375) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.756102 (0.017586) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.760061 (0.014857) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.760280 (0.015174) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.749943 (0.018780) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.758520 (0.017392) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.757640 (0.017649) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.756761 (0.015089) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "0.759181 (0.015416) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "0.749063 (0.018755) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.757421 (0.018840) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.757420 (0.018765) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.757421 (0.018450) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.758519 (0.015939) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.746864 (0.020114) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.753462 (0.020637) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.751482 (0.021418) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "0.753462 (0.020637) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "0.755001 (0.020808) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "0.743345 (0.016467) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.746205 (0.020118) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.745546 (0.022023) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "0.747085 (0.021764) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.746864 (0.024150) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.717391 (0.030989) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "0.740265 (0.020945) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "0.740488 (0.020509) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "0.740705 (0.019186) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "0.740485 (0.018096) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "0.633163 (0.019988) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.643937 (0.035078) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.642178 (0.032605) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "0.633163 (0.019988) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.649214 (0.042507) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/Users/minhhienvo/opt/miniconda3/envs/tensorflow/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=11, kernel_initializer='uniform', activation='softmax', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=40, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5df2f",
   "metadata": {},
   "source": [
    "### 7. Tune the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c7ae469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_13765/1691992900.py:27: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=40, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.755819 using {'neurons': 30}\n",
      "0.740233 (0.007913) with: {'neurons': 1}\n",
      "0.748699 (0.008631) with: {'neurons': 5}\n",
      "0.753510 (0.005961) with: {'neurons': 10}\n",
      "0.752739 (0.011311) with: {'neurons': 15}\n",
      "0.751779 (0.005033) with: {'neurons': 20}\n",
      "0.753896 (0.003984) with: {'neurons': 22}\n",
      "0.751585 (0.009374) with: {'neurons': 25}\n",
      "0.755819 (0.005052) with: {'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the number of neurons\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=11, kernel_initializer='uniform', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=40, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 22, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc1308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
