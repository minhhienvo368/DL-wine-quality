{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d78327",
   "metadata": {},
   "source": [
    "# How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a168e7",
   "metadata": {},
   "source": [
    "    * I apply this guidelines for my project, working with wine quality prediction database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc99b44",
   "metadata": {},
   "source": [
    "    1. How to use Keras models in scikit-learn.\n",
    "    2. How to use grid search in scikit-learn.\n",
    "    3. How to tune batch size and training epochs.\n",
    "    4. How to tune optimization algorithms.\n",
    "    5. How to tune learning rate and momentum.\n",
    "    6. How to tune network weight initialization.\n",
    "    7. How to tune activation functions.\n",
    "    8. How to tune dropout regularization.\n",
    "    9. How to tune the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a8313",
   "metadata": {},
   "source": [
    "Grid search is a model hyperparameter optimization technique. In scikit-learn this technique is provided in the GridSearchCV class. By default, accuracy is the score that is optimized, but other scores can be specified in the score argument of the GridSearchCV constructor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d77bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import matplotlib.pyplot as plt    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from tensorflow import keras \n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d71070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 11)\n",
      "(6497,)\n"
     ]
    }
   ],
   "source": [
    "#Import and standardize database\n",
    "\n",
    "df = pd.read_csv(\"wine.csv\", index_col = \"index\")\n",
    "X = df.iloc[:, 0:11]\n",
    "df['quality'] = df['quality'].apply(lambda x: 0 if x <= 6 else 1)\n",
    "y = df.iloc[:, 11]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.30)\n",
    "# creating normalization object \n",
    "# fit data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9483da",
   "metadata": {},
   "source": [
    "## Use Grid Search in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf109c",
   "metadata": {},
   "source": [
    "### 1. Tune optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e715d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/48r1p7j10ys5bbndt2lmfpk40000gp/T/ipykernel_1373/3954041031.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
      "2021-09-08 21:05:24.971411: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:24.972362: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:24.975349: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:24.979139: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:25.000925: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:25.068013: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:25.078415: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-08 21:05:25.095271: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# define the grid search Parameters ###OPTIMIZERS\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)   ##Define changes here\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3680db3c",
   "metadata": {},
   "source": [
    "The results show that the Best Optimizer with accuracy rate: 0.829338 using {'optimizer': 'Nadam'}\n",
    "\n",
    "    + 0.824277 (0.008811) with: {'optimizer': 'SGD'}\n",
    "    + 0.825817 (0.007051) with: {'optimizer': 'RMSprop'}\n",
    "    + 0.816804 (0.007600) with: {'optimizer': 'Adagrad'}\n",
    "    + 0.743341 (0.030207) with: {'optimizer': 'Adadelta'}\n",
    "    + 0.823180 (0.003760) with: {'optimizer': 'Adam'}\n",
    "    + 0.824059 (0.007360) with: {'optimizer': 'Adamax'}\n",
    "    + 0.829338 (0.001606) with: {'optimizer': 'Nadam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee002b5",
   "metadata": {},
   "source": [
    "### 2. Tune batch size and training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d558b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# fix random seed for reproducibility\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters: BATCH_SIZE and EPOCHS\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs) #define parameters here\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00fceb",
   "metadata": {},
   "source": [
    "With the optimizer 'Nadam', activation = 'relu', loss = 'binary_crossentropy', the results show that:\n",
    "\n",
    "+ Best: 0.832858 using {'batch_size': 40, 'epochs': 100}\n",
    "    * 0.820101 (0.005428) with: {'batch_size': 10, 'epochs': 10}\n",
    "    * 0.828018 (0.001897) with: {'batch_size': 10, 'epochs': 50}\n",
    "    * 0.819880 (0.004991) with: {'batch_size': 10, 'epochs': 100}\n",
    "    * 0.822301 (0.003650) with: {'batch_size': 20, 'epochs': 10}\n",
    "    * 0.822300 (0.002061) with: {'batch_size': 20, 'epochs': 50}\n",
    "    * 0.824279 (0.004420) with: {'batch_size': 20, 'epochs': 100}\n",
    "    * 0.825601 (0.005262) with: {'batch_size': 40, 'epochs': 10}\n",
    "    * 0.822520 (0.004693) with: {'batch_size': 40, 'epochs': 50}\n",
    "    * 0.832858 (0.005421) with: {'batch_size': 40, 'epochs': 100}\n",
    "    * 0.817902 (0.004257) with: {'batch_size': 60, 'epochs': 10}\n",
    "    * 0.824499 (0.003332) with: {'batch_size': 60, 'epochs': 50}\n",
    "    * 0.829338 (0.001085) with: {'batch_size': 60, 'epochs': 100}\n",
    "    * 0.817904 (0.005569) with: {'batch_size': 80, 'epochs': 10}\n",
    "    * 0.822740 (0.003683) with: {'batch_size': 80, 'epochs': 50}\n",
    "    * 0.825158 (0.005721) with: {'batch_size': 80, 'epochs': 100}\n",
    "    * 0.817904 (0.009358) with: {'batch_size': 100, 'epochs': 10}\n",
    "    * 0.825379 (0.005659) with: {'batch_size': 100, 'epochs': 50}\n",
    "    * 0.825599 (0.004500) with: {'batch_size': 100, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c054cea",
   "metadata": {},
   "source": [
    "### 3. Tune learning rate and momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learning_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learning_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "# define the grid search parameters\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train) # modify features here\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521350be",
   "metadata": {},
   "source": [
    "### With unidentified Optimizer, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee2bf1",
   "metadata": {},
   "source": [
    "### 4. Tune network weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode='uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode= init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb6b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797a6941",
   "metadata": {},
   "source": [
    "### 5. Tune activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the dropout rate\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=11, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cada021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4514fc",
   "metadata": {},
   "source": [
    "### 6. Tune dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17984d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5b5df2f",
   "metadata": {},
   "source": [
    "### 7. Tune the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ae469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the number of neurons\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=8, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=40, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 22, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd17c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
